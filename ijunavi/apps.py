from django.apps import AppConfig
import os
import pandas as pd
import zipfile
import requests
from pathlib import Path

import gradio as gr
from dotenv import load_dotenv

from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_chroma import Chroma
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA

class IjunaviConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'ijunavi'


# ç’°å¢ƒå¤‰æ•°ã‚’ãƒ­ãƒ¼ãƒ‰
load_dotenv()

# === è¨­å®š ===
DATA_DIR = "./data"
DB_DIR = "./chroma_db/migration"

# å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨è§£å‡ï¼ˆä»»æ„ï¼‰
def download_and_extract_data():
    dropbox_url = "https://www.dropbox.com/scl/fo/53hp5xxh8jo08t8ckhvyf/APEhI4MajStJbSYZClqvK0k?rlkey=4s5bwt71v39tfp4v075f4xi1l&st=n8dnqbjz&dl=1"
    zip_path = "rag_handson.zip"
    extract_dir = "rag_handson"

    if not os.path.exists(extract_dir):
        print("Downloading ZIP from Dropbox...")
        try:
            with requests.get(dropbox_url, stream=True) as r:
                r.raise_for_status()
                with open(zip_path, "wb") as f:
                    for chunk in r.iter_content(chunk_size=8192):
                        f.write(chunk)
            print("Download complete.")

            print("Extracting ZIP...")
            with zipfile.ZipFile(zip_path, "r") as zip_ref:
                zip_ref.extractall(extract_dir)
            print("Extraction complete.")
        except Exception as e:
            print(f"ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯è§£å‡ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®èª­ã¿è¾¼ã¿ã¨ãƒãƒ£ãƒ³ã‚¯åŒ–
def load_and_split_documents():
    docs = []
    # PDFã®èª­ã¿è¾¼ã¿
    for path in Path(DATA_DIR).rglob("*.pdf"):
        try:
            loader = PyPDFLoader(str(path))
            docs.extend(loader.load())
        except Exception as e:
            print(f"{path.name} ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    # CSVã®èª­ã¿è¾¼ã¿ï¼ˆPandasã‚’ä½¿ç”¨ï¼‰
    for path in Path(DATA_DIR).rglob("*.csv"):
        try:
            df = pd.read_csv(str(path))
            # å„è¡Œã‚’æ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨ã—ã¦è¿½åŠ 
            for _, row in df.iterrows():
                doc_content = f"ãƒ•ã‚¡ã‚¤ãƒ«: {path.name}\nå†…å®¹: {row.to_json(orient='index', force_ascii=False)}"
                docs.append({"page_content": doc_content, "metadata": {"source": str(path.name)}})
        except Exception as e:
            print(f" {path.name} ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    print(f" {len(docs)} ä»¶ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")

    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    chunks = splitter.split_documents(docs)
    print(f" {len(chunks)} å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã•ã‚Œã¾ã—ãŸã€‚")
    return chunks

# ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®åˆæœŸåŒ–
def initialize_vectorstore(chunks):
    if os.path.exists(DB_DIR) and os.path.isdir(DB_DIR):
        print(" æ—¢å­˜ã®ãƒ™ã‚¯ãƒˆãƒ«DBã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚")
        vectorstore = Chroma(
            persist_directory=DB_DIR,
            embedding_function=OpenAIEmbeddings()
        )
    else:
        print(" æ–°ã—ã„ãƒ™ã‚¯ãƒˆãƒ«DBã‚’ä½œæˆã—ã¾ã™...")
        embeddings = OpenAIEmbeddings()
        vectorstore = Chroma.from_documents(
            chunks,
            embeddings,
            persist_directory=DB_DIR
        )
        print(" ãƒ™ã‚¯ãƒˆãƒ«DBã®ä½œæˆã¨ä¿å­˜ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

    return vectorstore

# QAãƒã‚§ãƒ¼ãƒ³ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
def setup_qa_chain(vectorstore):
    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.0)
    retriever = vectorstore.as_retriever(search_kwargs={"k": 5}) # é–¢é€£æ€§ã®é«˜ã„ä¸Šä½5ä»¶ã‚’æ¤œç´¢

    template = """ã‚ãªãŸã¯åœ°æ–¹ç§»ä½ã®å°‚é–€å®¶ã§ã™ã€‚
    æä¾›ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã¨ã‚ãªãŸã®çŸ¥è­˜ã‚’ä½¿ã£ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åœ°æ–¹ç§»ä½ã«é–¢ã™ã‚‹è³ªå•ã«è¦ªåˆ‡ã‹ã¤å…·ä½“çš„ã«ç­”ãˆã¦ãã ã•ã„ã€‚
    ææ¡ˆã™ã‚‹åœ°åŸŸã¯ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå†…ã®æƒ…å ±ã«åŸºã¥ã„ã¦ãã ã•ã„ã€‚
    ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«æƒ…å ±ãŒãªã„å ´åˆã¯ã€ã€Œæƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€å…·ä½“çš„ãªææ¡ˆãŒã§ãã¾ã›ã‚“ã€ã¨ç­”ãˆã¦ãã ã•ã„ã€‚

    ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:
    {context}

    è³ªå•:
    {question}
    """

    prompt = PromptTemplate.from_template(template)

    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriever,
        chain_type="stuff",
        chain_type_kwargs={"prompt": prompt},
        return_source_documents=True
    )
    return qa_chain

# å›ç­”é–¢æ•°
def chat_response(message, history):
    try:
        result = qa_chain.invoke({"query": message})
        answer = result.get("result", "æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€å…·ä½“çš„ãªææ¡ˆãŒã§ãã¾ã›ã‚“ã€‚")
        sources = result.get("source_documents", [])

        formatted_sources = []
        if sources:
            for i, doc in enumerate(sources):
                title = doc.metadata.get("source", f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ{i+1}")
                snippet = doc.page_content.strip().replace("\n", " ").replace("ã€€", " ")
                snippet = snippet[:300] + ("â€¦" if len(snippet) > 300 else "")
                formatted_sources.append(f"""ã€{i+1}. {title}ã€‘\n{snippet}""")

            sources_text = "\n---\n".join(formatted_sources)
            full_response = f"{answer}\n\nğŸ“„ **å‚ç…§ãƒ‡ãƒ¼ã‚¿**\n{sources_text}"
        else:
            full_response = answer

        return full_response
    except Exception as e:
        import traceback
        traceback.print_exc()
        return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
if __name__ == "__main__":
    # ãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆåˆå›å®Ÿè¡Œæ™‚ã®ã¿ï¼‰
    download_and_extract_data()

    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®èª­ã¿è¾¼ã¿ã¨ãƒ™ã‚¯ãƒˆãƒ«DBã®æ§‹ç¯‰
    chunks = load_and_split_documents()
    vectorstore = initialize_vectorstore(chunks)

    # QAãƒã‚§ãƒ¼ãƒ³ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    qa_chain = setup_qa_chain(vectorstore)

    # Gradio UIã®èµ·å‹•
    ui = gr.ChatInterface(
        fn=chat_response,
        title="åœ°æ–¹ç§»ä½ã‚³ãƒ³ã‚·ã‚§ãƒ«ã‚¸ãƒ¥ï¼ˆRAGï¼‰",
        description="ã‚ãªãŸã®å¸Œæœ›æ¡ä»¶ã«åˆã£ãŸåœ°æ–¹ç§»ä½å…ˆã‚’ææ¡ˆã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã¯e-Statã€ä¸å‹•ç”£ã€äº¤é€šæƒ…å ±ã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚",
        examples=["å­è‚²ã¦ãŒã—ã‚„ã™ã„åœ°åŸŸã‚’æ•™ãˆã¦ãã ã•ã„", "é™ã‹ã§è‡ªç„¶è±Šã‹ãªåœ°åŸŸã§ã€å®¶è³ƒãŒå®‰ã„ã¨ã“ã‚ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ"],
        submit_btn="é€ä¿¡",
        stop_btn="åœæ­¢"
    )
    ui.launch()